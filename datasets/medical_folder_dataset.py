# datasets/medical_folder_dataset.py
import os
import json
import torch
import numpy as np
from PIL import Image, ImageDraw
from torch.utils.data import Dataset

class MedicalFolderDataset(Dataset):
    """
    í´ë” êµ¬ì¡° ê¸°ë°˜ ì˜ë£Œ ì˜ìƒ Dataset (LabelMe JSON)
    
    êµ¬ì¡°:
    1.ì›ì²œë°ì´í„°/
        â””â”€â”€ ëŒ€ì¥/
        â”œâ”€â”€ ê¶¤ì–‘/
        â”œâ”€â”€ ì•”/
        â””â”€â”€ ì¢…ì–‘/
    
    2.ë¼ë²¨ë§ë°ì´í„°/
        â””â”€â”€ ëŒ€ì¥/
        â”œâ”€â”€ ê¶¤ì–‘/
        â”‚   â”œâ”€â”€ image1.json (LabelMe format)
        â”œâ”€â”€ ì•”/
        â””â”€â”€ ì¢…ì–‘/
    """
    
    # JSONì˜ lesion ì½”ë“œ â†’ ìš°ë¦¬ í´ë˜ìŠ¤ ID
    LESION_CODE_TO_IDX = {
        0: 1,  # ê¶¤ì–‘ â†’ 1
        1: 3,  # ì¢…ì–‘ â†’ 3 (ì¶”ì •)
        2: 2,  # ì•” â†’ 2
        3: 3,  # ì¢…ì–‘ â†’ 3 (ì˜ˆë¹„)
    }
    
    IDX_TO_CLASS = {
        1: 'ê¶¤ì–‘ (ulcer)',
        2: 'ì•” (cancer)',
        3: 'ì¢…ì–‘ (tumor)'
    }
    
    def __init__(self, 
                image_root, 
                label_root, 
                organ_type='ëŒ€ì¥',
                transforms=None,
                min_area=100):  # ë„ˆë¬´ ì‘ì€ annotation í•„í„°ë§
        """
        Args:
            image_root: ì›ì²œë°ì´í„° í´ë” (1.ì›ì²œë°ì´í„°)
            label_root: ë¼ë²¨ë§ë°ì´í„° í´ë” (2.ë¼ë²¨ë§ë°ì´í„°)
            organ_type: 'ëŒ€ì¥' or 'ìœ„'
            transforms: torchvision transforms
            min_area: ìµœì†Œ annotation ë©´ì  (í”½ì…€)
        """
        self.image_root = image_root
        self.label_root = label_root
        self.organ_type = organ_type
        self.transforms = transforms
        self.min_area = min_area
        
        # ìƒ˜í”Œ ìˆ˜ì§‘
        self.samples = []
        organ_img_path = os.path.join(image_root, organ_type)
        organ_label_path = os.path.join(label_root, organ_type)
        
        class_names = ['ê¶¤ì–‘', 'ì•”', 'ì¢…ì–‘']
        
        for class_name in class_names:
            img_class_dir = os.path.join(organ_img_path, class_name)
            label_class_dir = os.path.join(organ_label_path, class_name)
            
            if not os.path.isdir(img_class_dir):
                continue
            
            # ì´ë¯¸ì§€ íŒŒì¼ ìˆœíšŒ
            for img_name in os.listdir(img_class_dir):
                if not img_name.lower().endswith(('.png', '.jpg', '.jpeg')):
                    continue
                
                img_path = os.path.join(img_class_dir, img_name)
                
                # ëŒ€ì‘í•˜ëŠ” JSON íŒŒì¼ ì°¾ê¸°
                json_name = os.path.splitext(img_name)[0] + '.json'
                json_path = os.path.join(label_class_dir, json_name)
                
                if os.path.exists(json_path):
                    self.samples.append({
                        'image_path': img_path,
                        'json_path': json_path,
                        'class_name': class_name
                    })
        
        print(f"\nğŸ“Š {organ_type} Dataset loaded:")
        print(f"  Total samples: {len(self.samples)}")
        
        # í´ë˜ìŠ¤ë³„ ê°œìˆ˜
        from collections import Counter
        class_counts = Counter(s['class_name'] for s in self.samples)
        for class_name, count in sorted(class_counts.items()):
            print(f"  {class_name}: {count} samples")
    
    def __len__(self):
        return len(self.samples)
    
    def _polygon_to_mask(self, points, img_width, img_height):
        """Polygon ì¢Œí‘œë¥¼ binary maskë¡œ ë³€í™˜"""
        mask_img = Image.new('L', (img_width, img_height), 0)
        
        # pointsë¥¼ tuple listë¡œ ë³€í™˜
        polygon = [tuple(p) for p in points]
        
        # Polygon ê·¸ë¦¬ê¸°
        ImageDraw.Draw(mask_img).polygon(polygon, outline=1, fill=1)
        
        return np.array(mask_img, dtype=np.uint8)
    
    def _parse_labelme_json(self, json_path, img_width, img_height):
        """
        LabelMe JSONì„ Mask R-CNN í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        """
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        boxes = []
        labels = []
        masks = []
        areas = []
        
        shapes = data.get('shapes', [])
        
        for shape in shapes:
            points = shape['points']
            lesion_code = shape.get('lesion', 0)
            
            # Lesion codeë¥¼ class indexë¡œ ë³€í™˜
            class_idx = self.LESION_CODE_TO_IDX.get(lesion_code, 1)
            
            # Pointsë¥¼ numpy arrayë¡œ
            points_array = np.array(points)
            
            # Bounding box ê³„ì‚°
            x_coords = points_array[:, 0]
            y_coords = points_array[:, 1]
            
            x1, y1 = x_coords.min(), y_coords.min()
            x2, y2 = x_coords.max(), y_coords.max()
            
            # ë„ˆë¬´ ì‘ì€ bbox í•„í„°ë§
            area = (x2 - x1) * (y2 - y1)
            if area < self.min_area:
                continue
            
            boxes.append([x1, y1, x2, y2])
            labels.append(class_idx)
            areas.append(area)
            
            # Polygon â†’ Mask
            mask = self._polygon_to_mask(points, img_width, img_height)
            masks.append(mask)
        
        # Tensor ë³€í™˜
        if len(boxes) == 0:
            # ë¹ˆ annotationì¸ ê²½ìš° (í•™ìŠµ ì‹œ ë¬¸ì œê°€ ë  ìˆ˜ ìˆìŒ)
            boxes = torch.zeros((0, 4), dtype=torch.float32)
            labels = torch.zeros((0,), dtype=torch.int64)
            masks = torch.zeros((0, img_height, img_width), dtype=torch.uint8)
            areas = torch.zeros((0,), dtype=torch.float32)
        else:
            boxes = torch.as_tensor(boxes, dtype=torch.float32)
            labels = torch.as_tensor(labels, dtype=torch.int64)
            masks = torch.as_tensor(np.stack(masks), dtype=torch.uint8)
            areas = torch.as_tensor(areas, dtype=torch.float32)
        
        return boxes, labels, masks, areas
    
    def __getitem__(self, idx):
        sample = self.samples[idx]
        
        # ì´ë¯¸ì§€ ë¡œë“œ
        image = Image.open(sample['image_path']).convert('RGB')
        img_width, img_height = image.size
        
        # Annotation íŒŒì‹±
        boxes, labels, masks, areas = self._parse_labelme_json(
            sample['json_path'],
            img_width,
            img_height
        )
        
        # Target êµ¬ì„±
        target = {
            'boxes': boxes,
            'labels': labels,
            'masks': masks,
            'image_id': torch.tensor([idx]),
            'area': areas,
            'iscrowd': torch.zeros((len(boxes),), dtype=torch.int64)
        }
        
        if self.transforms:
            image = self.transforms(image)
        
        return image, target


# ë¹ˆ annotation í•„í„°ë§í•˜ëŠ” collate function
def collate_fn_filter_empty(batch):
    """ë¹ˆ annotationì„ ê°€ì§„ ìƒ˜í”Œ ì œê±°"""
    batch = [(img, target) for img, target in batch 
            if len(target['boxes']) > 0]
    
    if len(batch) == 0:
        # ëª¨ë“  ìƒ˜í”Œì´ ë¹„ì–´ìˆìœ¼ë©´ ë”ë¯¸ ë°˜í™˜
        return None
    
    return tuple(zip(*batch))