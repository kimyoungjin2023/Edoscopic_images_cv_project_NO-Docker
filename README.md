# AI Hub ë‚´ì‹œê²½ ì´ë¯¸ì§€ - Mask R-CNN í”„ë¡œì íŠ¸

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-red)](https://pytorch.org/)
[![License](https://img.shields.io/badge/License-MIT-green)](LICENSE)

ResNet50 backboneì„ ì‚¬ìš©í•˜ëŠ” Mask R-CNN ëª¨ë¸ë¡œ AI Hub ë‚´ì‹œê²½ ì´ë¯¸ì§€ì— ëŒ€í•´ **Classification, Object Detection, Instance Segmentation**ì„ ë™ì‹œì— ìˆ˜í–‰í•˜ëŠ” í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤.

---

## ğŸ“‹ ëª©ì°¨

- [í”„ë¡œì íŠ¸ ê°œìš”](#í”„ë¡œì íŠ¸-ê°œìš”)
- [ë°ì´í„°ì…‹ ì •ë³´](#ë°ì´í„°ì…‹-ì •ë³´)
- [ëª¨ë¸ êµ¬ì¡°](#ëª¨ë¸-êµ¬ì¡°)
- [ì„¤ì¹˜ ë°©ë²•](#ì„¤ì¹˜-ë°©ë²•)
- [ë°ì´í„° ì¤€ë¹„](#ë°ì´í„°-ì¤€ë¹„)
- [í•™ìŠµ](#í•™ìŠµ)
- [í‰ê°€](#í‰ê°€)
- [ì¶”ë¡ ](#ì¶”ë¡ )
- [í”„ë¡œì íŠ¸ êµ¬ì¡°](#í”„ë¡œì íŠ¸-êµ¬ì¡°)

---

## ğŸ¯ í”„ë¡œì íŠ¸ ê°œìš”

### ëª©í‘œ
í•˜ë‚˜ì˜ Mask R-CNN ëª¨ë¸ë¡œ ë‚´ì‹œê²½ ì´ë¯¸ì§€ì—ì„œ:
1. **Classification**: ë³‘ë³€ ì¢…ë¥˜ ë¶„ë¥˜ (ê¶¤ì–‘, ìš©ì¢…, ì•”)
2. **Object Detection**: ë³‘ë³€ ìœ„ì¹˜ íƒì§€ (Bounding Box)
3. **Instance Segmentation**: ë³‘ë³€ ì˜ì—­ ë¶„í•  (Pixel-wise Mask)

### íŠ¹ì§•
- âœ… ResNet50 backbone (Conv layers only, FC ì œì™¸)
- âœ… FPN (Feature Pyramid Network)
- âœ… RPN (Region Proposal Network)
- âœ… RoIAlign
- âœ… Multi-task learning (Detection + Segmentation)
- âœ… ì˜ë£Œ ì˜ìƒ íŠ¹í™” ì „ì²˜ë¦¬
- âœ… ëª…í™•í•œ ë°ì´í„° ë¶„í•  (Train/Val/Test)

---

## ğŸ“Š ë°ì´í„°ì…‹ ì •ë³´

### AI Hub ë‚´ì‹œê²½ ì´ë¯¸ì§€ í•©ì„± ë°ì´í„°ì…‹

**ì¶œì²˜**: [AI Hub - ë‚´ì‹œê²½ ì´ë¯¸ì§€ í•©ì„±ë°ì´í„°](https://aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=data&dataSetSn=71666)

### ë°ì´í„° êµ¬ì„±
- **ì´ 40,000ì¥** (ìœ„ 20,000ì¥ + ëŒ€ì¥ 20,000ì¥)
- **ê³ í•´ìƒë„**: 2048 Ã— 2048 pixels
- **Annotation**: COCO-style JSON (bbox + segmentation mask)

### í´ë˜ìŠ¤ ì •ì˜

| Class ID | Class Name | Description |
|----------|------------|-------------|
| 0 | background | ë°°ê²½ |
| 1 | stomach_ulcer | ìœ„ ê¶¤ì–‘ |
| 2 | stomach_polyp | ìœ„ ìš©ì¢… |
| 3 | stomach_cancer | ìœ„ ì•” |
| 4 | colon_ulcer | ëŒ€ì¥ ê¶¤ì–‘ |
| 5 | colon_polyp | ëŒ€ì¥ ìš©ì¢… |
| 6 | colon_cancer | ëŒ€ì¥ ì•” |

### ë°ì´í„° ë¶„í• 

ë³¸ í”„ë¡œì íŠ¸ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ë°ì´í„°ë¥¼ ë¶„í• í•©ë‹ˆë‹¤:

| Split | í´ë˜ìŠ¤ë³„ ìƒ˜í”Œ ìˆ˜ | ì´ ìƒ˜í”Œ ìˆ˜ |
|-------|------------------|------------|
| **Train** | 1,000ì¥ | 6,000ì¥ |
| **Validation** | 150ì¥ | 900ì¥ |
| **Test** | 250-500ì¥ | 1,500-3,000ì¥ |

---

## ğŸ— ëª¨ë¸ êµ¬ì¡°

### Mask R-CNN Architecture

```
Input Image (3, H, W)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. Backbone: ResNet50                  â”‚
â”‚     - Conv layers only (No FC/MLP)      â”‚
â”‚     - Output: C2, C3, C4, C5            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. FPN (Feature Pyramid Network)       â”‚
â”‚     - Top-down pathway                  â”‚
â”‚     - Lateral connections               â”‚
â”‚     - Output: P2, P3, P4, P5            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. RPN (Region Proposal Network)       â”‚
â”‚     - 9 anchors per location            â”‚
â”‚     - Objectness + BBox regression      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. RoIAlign                             â”‚
â”‚     - Fixed-size feature extraction     â”‚
â”‚     - Box Head: 7Ã—7                     â”‚
â”‚     - Mask Head: 14Ã—14                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5a. Box Head      â”‚  5b. Mask Head     â”‚
â”‚   - Classification â”‚   - Segmentation   â”‚
â”‚   - BBox Regressionâ”‚   - Pixel-wise     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ì£¼ìš” êµ¬ì„± ìš”ì†Œ

1. **Backbone (ResNet50)**
   - ImageNet pretrained weights
   - Conv layersë§Œ ì‚¬ìš©
   - 4ê°œ scaleì˜ feature maps (C2, C3, C4, C5)

2. **FPN**
   - Multi-scale feature extraction
   - 256 channels per level

3. **RPN**
   - Anchor-based proposal generation
   - 3 scales Ã— 3 aspect ratios = 9 anchors

4. **RoI Heads**
   - Box predictor: Classification + BBox regression
   - Mask predictor: Instance segmentation

---

## ğŸ”§ ì„¤ì¹˜ ë°©ë²•

### 1. í™˜ê²½ ìš”êµ¬ì‚¬í•­

```bash
- Python >= 3.8
- CUDA >= 11.0 (GPU ì‚¬ìš© ì‹œ)
- PyTorch >= 2.0
```

### 2. íŒ¨í‚¤ì§€ ì„¤ì¹˜

```bash
# ë¦¬í¬ì§€í† ë¦¬ í´ë¡ 
git clone https://github.com/kimyoungjin2023/Edoscopic_images_cv_project_NO-Docker.git
cd Edoscopic_images_cv_project_NO-Docker

# í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install -r requirements.txt
```

ë˜ëŠ” ê°œë³„ ì„¤ì¹˜:

```bash
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121
pip install opencv-python albumentations pycocotools matplotlib tqdm pyyaml scikit-learn scipy
```

---

## ğŸ“‚ ë°ì´í„° ì¤€ë¹„

### 1. AI Hub ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ

AI Hubì—ì„œ "ë‚´ì‹œê²½ ì´ë¯¸ì§€ í•©ì„±ë°ì´í„°"ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ê³  ì••ì¶•ì„ í•´ì œí•©ë‹ˆë‹¤.

### 2. ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
data/
â”œâ”€â”€ 01.ì›ì²œë°ì´í„°/
â”‚   â”œâ”€â”€ 1.ìœ„/
â”‚   â”‚   â”œâ”€â”€ 1.ê¶¤ì–‘/        # 5,000ì¥
â”‚   â”‚   â”œâ”€â”€ 2.ìš©ì¢…/        # 5,000ì¥
â”‚   â”‚   â””â”€â”€ 3.ì•”/          # 10,000ì¥
â”‚   â””â”€â”€ 2.ëŒ€ì¥/
â”‚       â”œâ”€â”€ 1.ê¶¤ì–‘/        # 5,000ì¥
â”‚       â”œâ”€â”€ 2.ìš©ì¢…/        # 5,000ì¥
â”‚       â””â”€â”€ 3.ì•”/          # 10,000ì¥
â””â”€â”€ 02.ë¼ë²¨ë§ë°ì´í„°/
    â”œâ”€â”€ 1.ìœ„/
    â”‚   â”œâ”€â”€ 1.ê¶¤ì–‘/        # JSON files
    â”‚   â”œâ”€â”€ 2.ìš©ì¢…/
    â”‚   â””â”€â”€ 3.ì•”/
    â””â”€â”€ 2.ëŒ€ì¥/
        â”œâ”€â”€ 1.ê¶¤ì–‘/
        â”œâ”€â”€ 2.ìš©ì¢…/
        â””â”€â”€ 3.ì•”/
```

### 3. JSON Annotation ì˜ˆì‹œ

```json
{
  "version": "4.2.7",
  "shapes": [
    {
      "label": "01_stomach_ulcer_generation",
      "organ": 0,
      "lesion": 0,
      "location": 1,
      "points": [[x1, y1], [x2, y2], ...],
      "shape_type": "polygon"
    }
  ],
  "imagePath": "1_1_03827.png",
  "imageHeight": 2048,
  "imageWidth": 2048
}
```

---

## ğŸš€ í•™ìŠµ

### ê¸°ë³¸ í•™ìŠµ

```bash
python train.py \
    --data-root ./data \
    --num-classes 7 \
    --epochs 50 \
    --batch-size 2 \
    --lr 0.005 \
    --output-dir ./checkpoints
```

### ì£¼ìš” íŒŒë¼ë¯¸í„°

#### ë°ì´í„° ì„¤ì •
```bash
--data-root                  # ë°ì´í„° ë£¨íŠ¸ ë””ë ‰í† ë¦¬
--train-samples-per-class    # í´ë˜ìŠ¤ë³„ í•™ìŠµ ìƒ˜í”Œ ìˆ˜ (ê¸°ë³¸: 1000)
--val-samples-per-class      # í´ë˜ìŠ¤ë³„ ê²€ì¦ ìƒ˜í”Œ ìˆ˜ (ê¸°ë³¸: 150)
--test-samples-per-class     # í´ë˜ìŠ¤ë³„ í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ìˆ˜ (ê¸°ë³¸: 400)
```

#### ëª¨ë¸ ì„¤ì •
```bash
--num-classes                # í´ë˜ìŠ¤ ê°œìˆ˜ (ê¸°ë³¸: 7)
--pretrained                 # ImageNet pretrained backbone ì‚¬ìš©
--trainable-backbone-layers  # í•™ìŠµ ê°€ëŠ¥í•œ backbone layer ìˆ˜ (0-5, ê¸°ë³¸: 5)
```

#### í•™ìŠµ ì„¤ì •
```bash
--epochs                     # ì´ epoch ìˆ˜ (ê¸°ë³¸: 50)
--batch-size                 # ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸: 2)
--lr                         # í•™ìŠµë¥  (ê¸°ë³¸: 0.005)
--momentum                   # SGD momentum (ê¸°ë³¸: 0.9)
--weight-decay               # ê°€ì¤‘ì¹˜ ê°ì‡  (ê¸°ë³¸: 0.0005)
--lr-scheduler               # LR scheduler (step/cosine/plateau)
--mixed-precision            # Mixed precision training
```

### í•™ìŠµ ì¬ê°œ

```bash
python train.py \
    --resume ./checkpoints/maskrcnn_epoch_020.pth \
    --epochs 50
```

### GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ

```bash
# ë°°ì¹˜ í¬ê¸° ê°ì†Œ
python train.py --batch-size 1

# ì´ë¯¸ì§€ í¬ê¸° ê°ì†Œ
python train.py --img-size 384 --batch-size 2

# Mixed precision training
python train.py --mixed-precision
```

---

## ğŸ“ˆ í‰ê°€

### Validation í‰ê°€

```bash
python eval.py \
    --data-root ./data \
    --checkpoint ./checkpoints/maskrcnn_best.pth \
    --split val \
    --conf-threshold 0.5
```

### Test í‰ê°€

```bash
python eval.py \
    --data-root ./data \
    --checkpoint ./checkpoints/maskrcnn_best.pth \
    --split test \
    --conf-threshold 0.5
```

### í‰ê°€ ë©”íŠ¸ë¦­

#### Detection Metrics
- **Precision**: TP / (TP + FP)
- **Recall**: TP / (TP + FN)
- **F1-Score**: 2 Ã— (Precision Ã— Recall) / (Precision + Recall)
- í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ ë¶„ì„

#### Segmentation Metrics
- **Dice Coefficient**: 2 Ã— |A âˆ© B| / (|A| + |B|)
- **IoU (Intersection over Union)**: |A âˆ© B| / |A âˆª B|

### ê²°ê³¼ ì €ì¥

í‰ê°€ ê²°ê³¼ëŠ” JSON í˜•ì‹ìœ¼ë¡œ ì €ì¥ë©ë‹ˆë‹¤:

```
eval_results/
â”œâ”€â”€ eval_results_val.json    # ê²€ì¦ ê²°ê³¼
â”œâ”€â”€ eval_results_test.json   # í…ŒìŠ¤íŠ¸ ê²°ê³¼
â””â”€â”€ predictions_test.pth      # ì˜ˆì¸¡ ê²°ê³¼ (optional)
```

---

## ğŸ” ì¶”ë¡ 

### ë‹¨ì¼ ì´ë¯¸ì§€ ì¶”ë¡ 

```bash
python inference.py \
    --input ./test_image.jpg \
    --checkpoint ./checkpoints/maskrcnn_best.pth \
    --conf-threshold 0.5 \
    --output-dir ./inference_results
```

### í´ë” ë‚´ ëª¨ë“  ì´ë¯¸ì§€ ì¶”ë¡ 

```bash
python inference.py \
    --input ./test_images/ \
    --checkpoint ./checkpoints/maskrcnn_best.pth \
    --output-dir ./inference_results
```

### ì¶œë ¥ ê²°ê³¼

ê° ì´ë¯¸ì§€ì— ëŒ€í•´ ë‹¤ìŒ íŒŒì¼ì´ ìƒì„±ë©ë‹ˆë‹¤:

1. **`[ì´ë¯¸ì§€ëª…]_overlay.jpg`**
   - ì›ë³¸ ì´ë¯¸ì§€ + Detection + Segmentation
   - ì‹¤ì œ ì‚¬ìš©ì— ì í•©

2. **`[ì´ë¯¸ì§€ëª…]_detailed.png`**
   - ì›ë³¸, Detection, Segmentationì„ ë‚˜ë€íˆ í‘œì‹œ
   - ë¶„ì„ ë° ê²€ì¦ìš©

### ì˜ˆì¸¡ ê²°ê³¼ í˜•ì‹

```python
{
    'boxes': [[x1, y1, x2, y2], ...],       # Bounding boxes
    'labels': [1, 3, 2, ...],               # Class IDs
    'scores': [0.95, 0.87, 0.82, ...],      # Confidence scores
    'masks': [mask1, mask2, mask3, ...]     # Segmentation masks
}
```

---

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
Edoscopic_images_cv_project_NO-Docker/
â”‚
â”œâ”€â”€ train.py                    # í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ eval.py                     # í‰ê°€ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ inference.py                # ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ requirements.txt            # í•„ìˆ˜ íŒ¨í‚¤ì§€
â”œâ”€â”€ README.md                   # í”„ë¡œì íŠ¸ ë¬¸ì„œ
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ mask_rcnn.py           # Mask R-CNN ëª¨ë¸ ì •ì˜
â”‚                              #   - ResNet50 backbone
â”‚                              #   - FPN, RPN, RoIAlign
â”‚                              #   - Box & Mask heads
â”‚
â”œâ”€â”€ datasets/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ dataset.py             # AI Hub ë°ì´í„°ì…‹ ë¡œë”
â”‚                              #   - COCO-style annotation íŒŒì‹±
â”‚                              #   - Train/Val/Test ë¶„í• 
â”‚                              #   - í´ë˜ìŠ¤ë³„ ìƒ˜í”Œë§
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ transforms.py          # ì˜ë£Œ ì˜ìƒ íŠ¹í™” Transform
â”‚   â”‚                          #   - CLAHE, Sharpen
â”‚   â”‚                          #   - Augmentation
â”‚   â””â”€â”€ engine.py              # í•™ìŠµ/í‰ê°€ ì—”ì§„
â”‚                              #   - Training loop
â”‚                              #   - Evaluation
â”‚                              #   - Metrics
â”‚
â”œâ”€â”€ checkpoints/               # ì²´í¬í¬ì¸íŠ¸ ì €ì¥ (ìë™ ìƒì„±)
â”‚   â”œâ”€â”€ maskrcnn_best.pth
â”‚   â””â”€â”€ maskrcnn_epoch_*.pth
â”‚
â”œâ”€â”€ eval_results/              # í‰ê°€ ê²°ê³¼ (ìë™ ìƒì„±)
â”‚   â””â”€â”€ eval_results_*.json
â”‚
â””â”€â”€ inference_results/         # ì¶”ë¡  ê²°ê³¼ (ìë™ ìƒì„±)
    â”œâ”€â”€ *_overlay.jpg
    â””â”€â”€ *_detailed.png
```

---

## ğŸ’¡ Tips & Best Practices

### í•™ìŠµ ê´€ë ¨

1. **Learning Rate Tuning**
   - ì´ˆê¸° LR: 0.005 (ë°°ì¹˜ í¬ê¸° 2 ê¸°ì¤€)
   - ë°°ì¹˜ í¬ê¸°ê°€ 2ë°° ì¦ê°€í•˜ë©´ LRë„ 2ë°° ì¦ê°€
   - Warmup ì‚¬ìš© ê¶Œì¥

2. **Data Augmentation**
   - ì˜ë£Œ ì˜ìƒ íŠ¹ì„± ê³ ë ¤
   - CLAHEë¡œ ì¡°ëª… ë¶ˆê· ì¼ ë³´ì •
   - Sharpenìœ¼ë¡œ í…ìŠ¤ì²˜ ê°•ì¡°
   - ê³¼ë„í•œ ë³€í˜•ì€ ì§€ì–‘

3. **ë°°ì¹˜ í¬ê¸°**
   - GPU ë©”ëª¨ë¦¬ì— ë”°ë¼ ì¡°ì • (1~4 ê¶Œì¥)
   - ì‘ì€ ë°°ì¹˜ì—ì„œëŠ” BatchNorm ëŒ€ì‹  GroupNorm ê³ ë ¤

### ì¶”ë¡  ê´€ë ¨

1. **Confidence Threshold**
   - ë†’ì€ ì •ë°€ë„: 0.7~0.9
   - ë†’ì€ ì¬í˜„ìœ¨: 0.3~0.5
   - ê· í˜•: 0.5 (ê¸°ë³¸ê°’)

2. **Post-processing**
   - NMS IoU threshold: 0.5 (ê¸°ë³¸ê°’)
   - ë„ˆë¬´ ì‘ì€ maskëŠ” í•„í„°ë§ ê³ ë ¤

---

## ğŸ› ë¬¸ì œ í•´ê²°

### CUDA Out of Memory

```bash
# í•´ê²° ë°©ë²• 1: ë°°ì¹˜ í¬ê¸° ê°ì†Œ
python train.py --batch-size 1

# í•´ê²° ë°©ë²• 2: ì´ë¯¸ì§€ í¬ê¸° ê°ì†Œ
python train.py --img-size 384

# í•´ê²° ë°©ë²• 3: Mixed precision training
python train.py --mixed-precision
```

### ë°ì´í„° ë¡œë”© ì˜¤ë¥˜

```python
# ë°ì´í„° ê²½ë¡œ í™•ì¸
python -c "from datasets.dataset import AIHubEndoscopicDataset; \
           dataset = AIHubEndoscopicDataset('./data', 'train')"
```

### Transform ì˜¤ë¥˜

```python
# Albumentations ë²„ì „ í™•ì¸
pip install albumentations==1.3.1 --upgrade
```

---

## ğŸ“š ì°¸ê³  ìë£Œ

### Papers
- [Mask R-CNN (He et al., 2017)](https://arxiv.org/abs/1703.06870)
- [ResNet (He et al., 2015)](https://arxiv.org/abs/1512.03385)
- [Feature Pyramid Networks (Lin et al., 2017)](https://arxiv.org/abs/1612.03144)

### Documentation
- [PyTorch Documentation](https://pytorch.org/docs/)
- [torchvision.models.detection](https://pytorch.org/vision/stable/models.html#object-detection-instance-segmentation-and-person-keypoint-detection)
- [Albumentations Documentation](https://albumentations.ai/docs/)

---

## ğŸ“ License

This project is licensed under the MIT License.

---

## ğŸ‘¥ Contributors

- OZ Coding School CV Study Team
- [kimyoungjin2023](https://github.com/kimyoungjin2023)

---

## ğŸ™ Acknowledgments

- AI Hub for providing the endoscopic image dataset
- PyTorch team for torchvision implementation
- Albumentations team for augmentation library

---

## ğŸ“§ Contact

ë¬¸ì˜ì‚¬í•­ì´ ìˆìœ¼ì‹œë©´ GitHub Issuesë¥¼ ì´ìš©í•´ ì£¼ì„¸ìš”.

---

**Happy Training! ğŸš€**
